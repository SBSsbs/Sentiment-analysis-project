{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                            Comment  Sentiment\n",
      "0           0     مقداد قداش مره تجيبوه افهمونا ماسط الشعب يحبوش          0\n",
      "1           1             karim gharbi masit i sitcom ma3jibnich          0\n",
      "2           2                                            mabldou          0\n",
      "3           3  الهالكا مختصه قناه الزيتونه محايده وانتهت مهمت...          0\n",
      "4           4  اتحاد الخراب والدمار خرب بلادنا يريدون افريقيا...          0\n"
     ]
    }
   ],
   "source": [
    "data1 = pd.read_excel(r\"output.xlsx\")\n",
    "print(data1.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>مقداد قداش مره تجيبوه افهمونا ماسط الشعب يحبوش</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>karim gharbi masit i sitcom ma3jibnich</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>mabldou</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>الهالكا مختصه قناه الزيتونه محايده وانتهت مهمت...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>اتحاد الخراب والدمار خرب بلادنا يريدون افريقيا...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>سلب لفلوسهم خاطر التوانسه فاقو بسرقتهم</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>المءسسات الخاصه المصانع يشملهم الاضراب</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>مدخل المقروض الاضراب يامعلم</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>والخاصه طز اخاطر يخلصو زوز فرنك السميك</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>اتحاد الخراب ينجح</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>اطمع يهز للهاويه بلاد شافه الافلاس والاتحاد هو...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>الاتحاد يتفاوظ الحكومه مداخيله الخاصه حل مشاكل...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>تشخر زادت بوف يهلك التحاد الخراب</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>مره ازيدنا كجيو القحوا اقلك نفاذ المخزون</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>الكميه ناقصه مشطلع سومها الحمد لله مرضنا وبرين...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>تفدلك 6 ملاين تتحصل عامين اطيشها الزبله الشعب ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>لقاح مشكوك</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>الكلام تقول صحيح تمنيك الشعب اتصور خطابكم وكلا...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>بلاد تنتج الشر</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>الغاز الماء يشملوا اطياف الشعب يهمهمش الخوانجيه</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>وزير يركب المرض</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>akhmaj etayaran tunisair nul</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>marra tisma33 7kaya jdida bled 7arfaa ken lmsa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>يهلكوو ماصيرو يتشد ماعندو هارب</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>lmohem tetlakch boulis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>عمله مسوده ذكي</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>walah te7chmou</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>الموظفين العمومين والنقابيين يتقاضون اجورا يقو...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>راجل كبير مانجم نحترم بياض شعرك ونمقط سواد وم...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>التفليم</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10364</th>\n",
       "      <td>10364</td>\n",
       "      <td>deux domaines b3ad lezmek takhtar haja maghro...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10365</th>\n",
       "      <td>10365</td>\n",
       "      <td>kenek parcours mte3ek maghrouma math info cot...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10366</th>\n",
       "      <td>10366</td>\n",
       "      <td>wa9tha kammel domaine kenek maghrouma s v t su...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10367</th>\n",
       "      <td>10367</td>\n",
       "      <td>sinon kenek belha9 dhay3a bin deux domaines</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10368</th>\n",
       "      <td>10368</td>\n",
       "      <td>akhtar thnia ashal a9sar médecine awel salaire...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10369</th>\n",
       "      <td>10369</td>\n",
       "      <td>aandek concours résidanat yta3ab weli yejem ma...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10370</th>\n",
       "      <td>10370</td>\n",
       "      <td>insat mpi ba3d 2 ans fama risque matekhouch br...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10371</th>\n",
       "      <td>10371</td>\n",
       "      <td>khrouj barra médecine tokhrej lezmek t3adi con...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10372</th>\n",
       "      <td>10372</td>\n",
       "      <td>sinon t9oss parcours mte3ek zone 4ème 5 ème an...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10373</th>\n",
       "      <td>10373</td>\n",
       "      <td>par contre insat tejem tpostuli campus france ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10374</th>\n",
       "      <td>10374</td>\n",
       "      <td>yjewbouk haja rare tel9aha domainet okhra wya3...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10375</th>\n",
       "      <td>10375</td>\n",
       "      <td>chouf l médecine lezem ta9ra 5 ans t3adi resid...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10376</th>\n",
       "      <td>10376</td>\n",
       "      <td>beh kenik thebha vas hawka l 5edma sbitarat 7a...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10377</th>\n",
       "      <td>10377</td>\n",
       "      <td>pour l ingénierie t5awelik ak4ar inik te5dem a...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10378</th>\n",
       "      <td>10378</td>\n",
       "      <td>filo5er makich moula l moul te5dem 5edmtik to5...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10379</th>\n",
       "      <td>10379</td>\n",
       "      <td>ak4ar mel medecine i9olik dentaire ena manins...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10380</th>\n",
       "      <td>10380</td>\n",
       "      <td>عسلامه ينجم يعاوني يفسرلي نتعامل جدتي مريضه زه...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10381</th>\n",
       "      <td>10381</td>\n",
       "      <td>ouii taadi aand tbib o shay</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10382</th>\n",
       "      <td>10382</td>\n",
       "      <td>labes otlob nsaya7 kifeh yelzem tet3amlou m3aha</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10383</th>\n",
       "      <td>10383</td>\n",
       "      <td>lina3rfou lzm tsayerha 5ater ta3k3sha tod5el b...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10384</th>\n",
       "      <td>10384</td>\n",
       "      <td>طريقه التعامل مهمه لازمها دواء ينقص الهلاوس</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10385</th>\n",
       "      <td>10385</td>\n",
       "      <td>ena jdati akaka lezm tsaysha 5atr mokhha mokh ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10386</th>\n",
       "      <td>10386</td>\n",
       "      <td>lezem thezouha l tbib fama dweyet inajem yaati...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10387</th>\n",
       "      <td>10387</td>\n",
       "      <td>o ntouma tahkiw maaha tabda aala hajet 9dom aa...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10388</th>\n",
       "      <td>10388</td>\n",
       "      <td>aham haja metbadelhash m blasetha maaneha l bl...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10389</th>\n",
       "      <td>10389</td>\n",
       "      <td>o5ti lezmk temchi m3aha fl5at chma3neha tsayer...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10390</th>\n",
       "      <td>10390</td>\n",
       "      <td>wrod belk tji dhedha 5ater m3 lwa9t thess rou7...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10391</th>\n",
       "      <td>10391</td>\n",
       "      <td>wblwa9t twali 3anifa wtonkorkom ahama haja 7a...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10392</th>\n",
       "      <td>10392</td>\n",
       "      <td>7ot l7aja hethi fibelk fita3amlok m3aha wchoft...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10393</th>\n",
       "      <td>10393</td>\n",
       "      <td>as3eb maredh memety mridha byh khaleha tahki k...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10394 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                            Comment  \\\n",
       "0               0     مقداد قداش مره تجيبوه افهمونا ماسط الشعب يحبوش   \n",
       "1               1             karim gharbi masit i sitcom ma3jibnich   \n",
       "2               2                                            mabldou   \n",
       "3               3  الهالكا مختصه قناه الزيتونه محايده وانتهت مهمت...   \n",
       "4               4  اتحاد الخراب والدمار خرب بلادنا يريدون افريقيا...   \n",
       "5               5             سلب لفلوسهم خاطر التوانسه فاقو بسرقتهم   \n",
       "6               6             المءسسات الخاصه المصانع يشملهم الاضراب   \n",
       "7               7                        مدخل المقروض الاضراب يامعلم   \n",
       "8               8             والخاصه طز اخاطر يخلصو زوز فرنك السميك   \n",
       "9               9                                  اتحاد الخراب ينجح   \n",
       "10             10  اطمع يهز للهاويه بلاد شافه الافلاس والاتحاد هو...   \n",
       "11             11  الاتحاد يتفاوظ الحكومه مداخيله الخاصه حل مشاكل...   \n",
       "12             12                   تشخر زادت بوف يهلك التحاد الخراب   \n",
       "13             13           مره ازيدنا كجيو القحوا اقلك نفاذ المخزون   \n",
       "14             14  الكميه ناقصه مشطلع سومها الحمد لله مرضنا وبرين...   \n",
       "15             15  تفدلك 6 ملاين تتحصل عامين اطيشها الزبله الشعب ...   \n",
       "16             16                                         لقاح مشكوك   \n",
       "17             17  الكلام تقول صحيح تمنيك الشعب اتصور خطابكم وكلا...   \n",
       "18             18                                     بلاد تنتج الشر   \n",
       "19             19    الغاز الماء يشملوا اطياف الشعب يهمهمش الخوانجيه   \n",
       "20             20                                    وزير يركب المرض   \n",
       "21             21                       akhmaj etayaran tunisair nul   \n",
       "22             22  marra tisma33 7kaya jdida bled 7arfaa ken lmsa...   \n",
       "23             23                     يهلكوو ماصيرو يتشد ماعندو هارب   \n",
       "24             24                             lmohem tetlakch boulis   \n",
       "25             25                                     عمله مسوده ذكي   \n",
       "26             26                                     walah te7chmou   \n",
       "27             27  الموظفين العمومين والنقابيين يتقاضون اجورا يقو...   \n",
       "28             28   راجل كبير مانجم نحترم بياض شعرك ونمقط سواد وم...   \n",
       "29             29                                            التفليم   \n",
       "...           ...                                                ...   \n",
       "10364       10364   deux domaines b3ad lezmek takhtar haja maghro...   \n",
       "10365       10365   kenek parcours mte3ek maghrouma math info cot...   \n",
       "10366       10366  wa9tha kammel domaine kenek maghrouma s v t su...   \n",
       "10367       10367       sinon kenek belha9 dhay3a bin deux domaines    \n",
       "10368       10368  akhtar thnia ashal a9sar médecine awel salaire...   \n",
       "10369       10369  aandek concours résidanat yta3ab weli yejem ma...   \n",
       "10370       10370  insat mpi ba3d 2 ans fama risque matekhouch br...   \n",
       "10371       10371  khrouj barra médecine tokhrej lezmek t3adi con...   \n",
       "10372       10372  sinon t9oss parcours mte3ek zone 4ème 5 ème an...   \n",
       "10373       10373  par contre insat tejem tpostuli campus france ...   \n",
       "10374       10374  yjewbouk haja rare tel9aha domainet okhra wya3...   \n",
       "10375       10375  chouf l médecine lezem ta9ra 5 ans t3adi resid...   \n",
       "10376       10376  beh kenik thebha vas hawka l 5edma sbitarat 7a...   \n",
       "10377       10377  pour l ingénierie t5awelik ak4ar inik te5dem a...   \n",
       "10378       10378  filo5er makich moula l moul te5dem 5edmtik to5...   \n",
       "10379       10379   ak4ar mel medecine i9olik dentaire ena manins...   \n",
       "10380       10380  عسلامه ينجم يعاوني يفسرلي نتعامل جدتي مريضه زه...   \n",
       "10381       10381                        ouii taadi aand tbib o shay   \n",
       "10382       10382    labes otlob nsaya7 kifeh yelzem tet3amlou m3aha   \n",
       "10383       10383  lina3rfou lzm tsayerha 5ater ta3k3sha tod5el b...   \n",
       "10384       10384        طريقه التعامل مهمه لازمها دواء ينقص الهلاوس   \n",
       "10385       10385  ena jdati akaka lezm tsaysha 5atr mokhha mokh ...   \n",
       "10386       10386  lezem thezouha l tbib fama dweyet inajem yaati...   \n",
       "10387       10387  o ntouma tahkiw maaha tabda aala hajet 9dom aa...   \n",
       "10388       10388  aham haja metbadelhash m blasetha maaneha l bl...   \n",
       "10389       10389  o5ti lezmk temchi m3aha fl5at chma3neha tsayer...   \n",
       "10390       10390  wrod belk tji dhedha 5ater m3 lwa9t thess rou7...   \n",
       "10391       10391   wblwa9t twali 3anifa wtonkorkom ahama haja 7a...   \n",
       "10392       10392  7ot l7aja hethi fibelk fita3amlok m3aha wchoft...   \n",
       "10393       10393  as3eb maredh memety mridha byh khaleha tahki k...   \n",
       "\n",
       "       Sentiment  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "5              0  \n",
       "6              0  \n",
       "7              0  \n",
       "8              1  \n",
       "9              1  \n",
       "10             1  \n",
       "11             0  \n",
       "12             1  \n",
       "13             0  \n",
       "14             0  \n",
       "15             0  \n",
       "16             0  \n",
       "17             0  \n",
       "18             0  \n",
       "19             0  \n",
       "20             0  \n",
       "21             1  \n",
       "22             1  \n",
       "23             1  \n",
       "24             0  \n",
       "25             0  \n",
       "26             1  \n",
       "27             0  \n",
       "28             0  \n",
       "29             0  \n",
       "...          ...  \n",
       "10364          3  \n",
       "10365          3  \n",
       "10366          3  \n",
       "10367          3  \n",
       "10368          3  \n",
       "10369          3  \n",
       "10370          3  \n",
       "10371          3  \n",
       "10372          3  \n",
       "10373          3  \n",
       "10374          3  \n",
       "10375          3  \n",
       "10376          3  \n",
       "10377          3  \n",
       "10378          3  \n",
       "10379          3  \n",
       "10380          3  \n",
       "10381          3  \n",
       "10382          3  \n",
       "10383          3  \n",
       "10384          3  \n",
       "10385          3  \n",
       "10386          3  \n",
       "10387          3  \n",
       "10388          3  \n",
       "10389          3  \n",
       "10390          3  \n",
       "10391          3  \n",
       "10392          3  \n",
       "10393          3  \n",
       "\n",
       "[10394 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data1.drop('Unnamed: 0', axis='columns', inplace=True)\n",
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4: Création du modèle de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into target and feature\n",
    "feature = data1.Comment.fillna(' ')\n",
    "target = data1.Sentiment\n",
    "# splitting into train and tests\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(feature, target, test_size =.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# create the transform\n",
    "vectorizer = TfidfVectorizer()\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(X_train)\n",
    "# summarize\n",
    "print(vectorizer.vocabulary_)\n",
    "print(vectorizer.idf_)\n",
    "# encode document\n",
    "vector = vectorizer.transform([X_train[0]])\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector1 = vectorizer.transform(X_train)\n",
    "vector2 = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_modif=vector1.toarray()\n",
    "X_test_modif=vector2.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_modif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pipeline\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "pipe = make_pipeline(LogisticRegression(solver='lbfgs',max_iter=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make param grid\n",
    "param_grid = {'logisticregression__C': [0.01, 0.1, 0.25, 0.75, 0.5, 1, 6,7,8,9,10,11,12,15,20, 100]}\n",
    "\n",
    "# create and fit the model\n",
    "model = GridSearchCV(pipe, param_grid, cv=5)\n",
    "model.fit(X_train_modif,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_modif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find accuracy, precision, recall:\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "new = np.asarray(Y_test)\n",
    "confusion_matrix(predictions,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(predictions,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# make prediction and print accuracy\n",
    "prediction = model.predict(X_test_modif)\n",
    "print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")\n",
    "print(classification_report(Y_test, prediction))\n",
    "\n",
    "precision = precision_score(Y_test, prediction, average='micro')\n",
    "recall = recall_score(Y_test, prediction, average='micro')\n",
    "accuracy = accuracy_score(Y_test, prediction)\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3), round(recall, 3), round(accuracy, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pipeline\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "param_C= [0.01, 0.1, 0.25, 0.75, 0.5, 1, 6,7,8,9,10,11,12,15,20, 100]\n",
    "algo=['newton-cg', 'liblinear','sag','saga','lbfgs']\n",
    "# create and fit the model\n",
    "\n",
    "for c in param_C:\n",
    "    for al in algo:\n",
    "        pipe = make_pipeline(TfidfVectorizer(),\n",
    "                    LogisticRegression(multi_class='multinomial', solver=al,C=c, max_iter=10000))\n",
    "    #model = GridSearchCV(pipe,  cv=5)\n",
    "    #model.fit(X_train,Y_train)\n",
    "        model.fit(X_train_modif,Y_train)\n",
    "        scores = cross_val_score(pipe, X_train_modif, Y_train, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "# report performance\n",
    "        print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "        #pipe.fit(X_train, Y_train)\n",
    "        #print('Accuracy for C=%s: %s'\n",
    "        # % (c, accuracy_score(Y_test, pipe.predict(X_test))))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# make prediction and print accuracy\n",
    "#prediction = model.predict(X_test)\n",
    "#print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")\n",
    "#print(classification_report(Y_test, prediction))\n",
    "\n",
    "#precision = precision_score(Y_test, prediction, average='micro')\n",
    "#recall = recall_score(Y_test, prediction, average='micro')\n",
    "#accuracy = accuracy_score(Y_test, prediction)\n",
    "#print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3), round(recall, 3), round(accuracy, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipe = make_pipeline(TfidfVectorizer(),\n",
    "#                    RandomForestClassifier())\n",
    "\n",
    "#param_grid = {'randomforestclassifier__n_estimators':[10, 100, 1000],\n",
    "  #           'randomforestclassifier__max_features':['sqrt', 'log2']}\n",
    "\n",
    "#rf_model = GridSearchCV(pipe, param_grid, cv=5)\n",
    "#rf_model.fit(X_train,Y_train)\n",
    "\n",
    "#prediction = rf_model.predict(X_test)\n",
    "#print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")\n",
    "\n",
    "#precision = precision_score(Y_test, predictionة average='micro')\n",
    "#recall = recall_score(Y_test, predictionة average='micro')\n",
    "#accuracy = accuracy_score(Y_test, prediction)\n",
    "#print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3), round(recall, 3), round(accuracy, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier (Multinomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipe = make_pipeline(TfidfVectorizer(),\n",
    "            #        MultinomialNB())\n",
    "#pipe.fit(X_train,Y_train)\n",
    "#prediction = pipe.predict(X_test)\n",
    "#print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")\n",
    "#print(classification_report(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipe = make_pipeline(TfidfVectorizer(),\n",
    "                   #  SVC())\n",
    "#param_grid = {'svc__kernel': ['rbf', 'linear', 'poly'],\n",
    "          ##   'svc__gamma': [0.1, 1, 10, 100],\n",
    "          #   'svc__C': [0.1, 1, 10, 100]}\n",
    "\n",
    "#svc_model = GridSearchCV(pipe, param_grid, cv=3)\n",
    "#svc_model.fit(X_train, Y_train)\n",
    "\n",
    "#prediction = svc_model.predict(X_test)\n",
    "#print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")\n",
    "#print(classification_report(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tous les autres modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "classifiers = [LinearSVC(), \n",
    "               SVC(gamma='auto'), \n",
    "               MultinomialNB(),\n",
    "               LogisticRegression(solver='liblinear',max_iter=10000),\n",
    "               BernoulliNB(), \n",
    "               SGDClassifier(), \n",
    "               DecisionTreeClassifier(max_depth=5),\n",
    "               RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "               KNeighborsClassifier(3)\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************\n",
      "Classifier= LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) and the ngrams is= 1\n",
      "Accuracy score is 0.73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.58      0.63       516\n",
      "           1       0.77      0.67      0.72       506\n",
      "           2       0.81      0.80      0.81       517\n",
      "           3       0.67      0.84      0.74       540\n",
      "\n",
      "    accuracy                           0.73      2079\n",
      "   macro avg       0.73      0.72      0.72      2079\n",
      "weighted avg       0.73      0.73      0.72      2079\n",
      "\n",
      "[[300  79  30  34]\n",
      " [ 74 340  10  19]\n",
      " [ 54   9 416  33]\n",
      " [ 88  78  61 454]]\n",
      "**************************************\n",
      "Classifier= SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False) and the ngrams is= 1\n",
      "Accuracy score is 0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      1.00      0.40       516\n",
      "           1       0.00      0.00      0.00       506\n",
      "           2       0.00      0.00      0.00       517\n",
      "           3       0.00      0.00      0.00       540\n",
      "\n",
      "    accuracy                           0.25      2079\n",
      "   macro avg       0.06      0.25      0.10      2079\n",
      "weighted avg       0.06      0.25      0.10      2079\n",
      "\n",
      "[[516 506 517 540]\n",
      " [  0   0   0   0]\n",
      " [  0   0   0   0]\n",
      " [  0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************\n",
      "Classifier= MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) and the ngrams is= 1\n",
      "Accuracy score is 0.73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.65      0.62       516\n",
      "           1       0.75      0.68      0.71       506\n",
      "           2       0.79      0.83      0.81       517\n",
      "           3       0.84      0.78      0.81       540\n",
      "\n",
      "    accuracy                           0.73      2079\n",
      "   macro avg       0.74      0.73      0.74      2079\n",
      "weighted avg       0.74      0.73      0.74      2079\n",
      "\n",
      "[[336 122  56  62]\n",
      " [ 82 343  16  18]\n",
      " [ 62  14 427  38]\n",
      " [ 36  27  18 422]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************\n",
      "Classifier= LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) and the ngrams is= 1\n",
      "Accuracy score is 0.71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.55      0.60       516\n",
      "           1       0.76      0.65      0.70       506\n",
      "           2       0.81      0.77      0.79       517\n",
      "           3       0.63      0.85      0.73       540\n",
      "\n",
      "    accuracy                           0.71      2079\n",
      "   macro avg       0.72      0.70      0.70      2079\n",
      "weighted avg       0.71      0.71      0.70      2079\n",
      "\n",
      "[[285  78  34  33]\n",
      " [ 70 328  16  18]\n",
      " [ 52  12 396  29]\n",
      " [109  88  71 460]]\n",
      "**************************************\n",
      "Classifier= BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True) and the ngrams is= 1\n",
      "Accuracy score is 0.61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.51      0.56       516\n",
      "           1       0.81      0.56      0.67       506\n",
      "           2       0.45      0.95      0.61       517\n",
      "           3       0.97      0.41      0.58       540\n",
      "\n",
      "    accuracy                           0.61      2079\n",
      "   macro avg       0.72      0.61      0.61      2079\n",
      "weighted avg       0.72      0.61      0.60      2079\n",
      "\n",
      "[[261  79  20  52]\n",
      " [ 42 285   5  19]\n",
      " [209 140 490 245]\n",
      " [  4   2   2 224]]\n",
      "**************************************\n",
      "Classifier= SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False) and the ngrams is= 1\n",
      "Accuracy score is 0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.57      0.63       516\n",
      "           1       0.76      0.68      0.72       506\n",
      "           2       0.80      0.80      0.80       517\n",
      "           3       0.66      0.84      0.74       540\n",
      "\n",
      "    accuracy                           0.72      2079\n",
      "   macro avg       0.73      0.72      0.72      2079\n",
      "weighted avg       0.73      0.72      0.72      2079\n",
      "\n",
      "[[296  73  25  31]\n",
      " [ 75 342  13  19]\n",
      " [ 56  13 416  38]\n",
      " [ 89  78  63 452]]\n",
      "**************************************\n",
      "Classifier= DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best') and the ngrams is= 1\n",
      "Accuracy score is 0.33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.04      0.07       516\n",
      "           1       1.00      0.08      0.15       506\n",
      "           2       0.76      0.19      0.31       517\n",
      "           3       0.28      0.98      0.44       540\n",
      "\n",
      "    accuracy                           0.33      2079\n",
      "   macro avg       0.72      0.32      0.24      2079\n",
      "weighted avg       0.71      0.33      0.24      2079\n",
      "\n",
      "[[ 19   4   0   0]\n",
      " [  0  40   0   0]\n",
      " [ 14   6 100  12]\n",
      " [483 456 417 528]]\n",
      "**************************************\n",
      "Classifier= RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features=1, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False) and the ngrams is= 1\n",
      "Accuracy score is 0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.99      0.40       516\n",
      "           1       0.40      0.00      0.01       506\n",
      "           2       0.80      0.01      0.02       517\n",
      "           3       0.64      0.01      0.03       540\n",
      "\n",
      "    accuracy                           0.25      2079\n",
      "   macro avg       0.52      0.25      0.11      2079\n",
      "weighted avg       0.52      0.25      0.11      2079\n",
      "\n",
      "[[513 503 511 531]\n",
      " [  2   2   0   1]\n",
      " [  0   0   4   1]\n",
      " [  1   1   2   7]]\n",
      "**************************************\n",
      "Classifier= KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
      "                     weights='uniform') and the ngrams is= 1\n",
      "Accuracy score is 0.42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.19      0.30       516\n",
      "           1       0.82      0.18      0.29       506\n",
      "           2       0.86      0.30      0.44       517\n",
      "           3       0.32      0.97      0.48       540\n",
      "\n",
      "    accuracy                           0.42      2079\n",
      "   macro avg       0.68      0.41      0.38      2079\n",
      "weighted avg       0.67      0.42      0.38      2079\n",
      "\n",
      "[[ 97  22  14   2]\n",
      " [ 12  90   4   4]\n",
      " [ 16   0 154   9]\n",
      " [391 394 345 525]]\n",
      "**************************************\n",
      "Classifier= LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) and the ngrams is= 2\n",
      "Accuracy score is 0.73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.56      0.62       516\n",
      "           1       0.76      0.67      0.72       506\n",
      "           2       0.81      0.81      0.81       517\n",
      "           3       0.66      0.85      0.74       540\n",
      "\n",
      "    accuracy                           0.73      2079\n",
      "   macro avg       0.73      0.72      0.72      2079\n",
      "weighted avg       0.73      0.73      0.72      2079\n",
      "\n",
      "[[289  70  27  32]\n",
      " [ 74 341  13  19]\n",
      " [ 54  12 419  30]\n",
      " [ 99  83  58 459]]\n",
      "**************************************\n",
      "Classifier= SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False) and the ngrams is= 2\n",
      "Accuracy score is 0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      1.00      0.40       516\n",
      "           1       0.00      0.00      0.00       506\n",
      "           2       0.00      0.00      0.00       517\n",
      "           3       0.00      0.00      0.00       540\n",
      "\n",
      "    accuracy                           0.25      2079\n",
      "   macro avg       0.06      0.25      0.10      2079\n",
      "weighted avg       0.06      0.25      0.10      2079\n",
      "\n",
      "[[516 506 517 540]\n",
      " [  0   0   0   0]\n",
      " [  0   0   0   0]\n",
      " [  0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************\n",
      "Classifier= MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) and the ngrams is= 2\n",
      "Accuracy score is 0.74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.66      0.62       516\n",
      "           1       0.76      0.68      0.72       506\n",
      "           2       0.79      0.83      0.81       517\n",
      "           3       0.84      0.78      0.81       540\n",
      "\n",
      "    accuracy                           0.74      2079\n",
      "   macro avg       0.74      0.74      0.74      2079\n",
      "weighted avg       0.74      0.74      0.74      2079\n",
      "\n",
      "[[340 122  54  61]\n",
      " [ 78 344  15  18]\n",
      " [ 62  14 430  40]\n",
      " [ 36  26  18 421]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************\n",
      "Classifier= LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) and the ngrams is= 2\n",
      "Accuracy score is 0.71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.54      0.60       516\n",
      "           1       0.76      0.66      0.71       506\n",
      "           2       0.80      0.76      0.78       517\n",
      "           3       0.62      0.85      0.72       540\n",
      "\n",
      "    accuracy                           0.71      2079\n",
      "   macro avg       0.72      0.70      0.70      2079\n",
      "weighted avg       0.72      0.71      0.70      2079\n",
      "\n",
      "[[280  72  30  33]\n",
      " [ 69 332  16  18]\n",
      " [ 54  13 395  29]\n",
      " [113  89  76 460]]\n",
      "**************************************\n",
      "Classifier= BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True) and the ngrams is= 2\n",
      "Accuracy score is 0.51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.45      0.51       516\n",
      "           1       0.88      0.44      0.59       506\n",
      "           2       0.37      0.97      0.54       517\n",
      "           3       0.99      0.18      0.31       540\n",
      "\n",
      "    accuracy                           0.51      2079\n",
      "   macro avg       0.71      0.51      0.49      2079\n",
      "weighted avg       0.71      0.51      0.49      2079\n",
      "\n",
      "[[231  70  13  68]\n",
      " [ 22 225   2   8]\n",
      " [262 211 502 366]\n",
      " [  1   0   0  98]]\n",
      "**************************************\n",
      "Classifier= SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False) and the ngrams is= 2\n",
      "Accuracy score is 0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.55      0.61       516\n",
      "           1       0.75      0.67      0.71       506\n",
      "           2       0.81      0.81      0.81       517\n",
      "           3       0.66      0.86      0.75       540\n",
      "\n",
      "    accuracy                           0.72      2079\n",
      "   macro avg       0.73      0.72      0.72      2079\n",
      "weighted avg       0.73      0.72      0.72      2079\n",
      "\n",
      "[[286  72  27  30]\n",
      " [ 78 338  14  18]\n",
      " [ 55  13 421  30]\n",
      " [ 97  83  55 462]]\n",
      "**************************************\n",
      "Classifier= DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best') and the ngrams is= 2\n",
      "Accuracy score is 0.33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.04      0.07       516\n",
      "           1       1.00      0.08      0.15       506\n",
      "           2       0.68      0.19      0.30       517\n",
      "           3       0.28      0.96      0.43       540\n",
      "\n",
      "    accuracy                           0.33      2079\n",
      "   macro avg       0.68      0.32      0.24      2079\n",
      "weighted avg       0.67      0.33      0.24      2079\n",
      "\n",
      "[[ 19   5   1   0]\n",
      " [  0  41   0   0]\n",
      " [ 14  11 100  22]\n",
      " [483 449 416 518]]\n",
      "**************************************\n",
      "Classifier= RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features=1, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False) and the ngrams is= 2\n",
      "Accuracy score is 0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.99      0.40       516\n",
      "           1       0.50      0.01      0.01       506\n",
      "           2       1.00      0.01      0.01       517\n",
      "           3       0.00      0.00      0.00       540\n",
      "\n",
      "    accuracy                           0.25      2079\n",
      "   macro avg       0.44      0.25      0.11      2079\n",
      "weighted avg       0.43      0.25      0.10      2079\n",
      "\n",
      "[[513 503 514 540]\n",
      " [  3   3   0   0]\n",
      " [  0   0   3   0]\n",
      " [  0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************\n",
      "Classifier= KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
      "                     weights='uniform') and the ngrams is= 2\n",
      "Accuracy score is 0.36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.13      0.22       516\n",
      "           1       0.88      0.11      0.20       506\n",
      "           2       0.90      0.20      0.32       517\n",
      "           3       0.29      0.99      0.45       540\n",
      "\n",
      "    accuracy                           0.36      2079\n",
      "   macro avg       0.70      0.36      0.30      2079\n",
      "weighted avg       0.70      0.36      0.30      2079\n",
      "\n",
      "[[ 65  15   7   1]\n",
      " [  4  57   3   1]\n",
      " [  7   0 101   4]\n",
      " [440 434 406 534]]\n",
      "**************************************\n",
      "Classifier= LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) and the ngrams is= 3\n",
      "Accuracy score is 0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.56      0.62       516\n",
      "           1       0.77      0.67      0.72       506\n",
      "           2       0.81      0.81      0.81       517\n",
      "           3       0.66      0.85      0.74       540\n",
      "\n",
      "    accuracy                           0.72      2079\n",
      "   macro avg       0.73      0.72      0.72      2079\n",
      "weighted avg       0.73      0.72      0.72      2079\n",
      "\n",
      "[[288  69  27  30]\n",
      " [ 73 340  13  18]\n",
      " [ 55  14 418  31]\n",
      " [100  83  59 461]]\n",
      "**************************************\n",
      "Classifier= SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False) and the ngrams is= 3\n",
      "Accuracy score is 0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      1.00      0.40       516\n",
      "           1       0.00      0.00      0.00       506\n",
      "           2       0.00      0.00      0.00       517\n",
      "           3       0.00      0.00      0.00       540\n",
      "\n",
      "    accuracy                           0.25      2079\n",
      "   macro avg       0.06      0.25      0.10      2079\n",
      "weighted avg       0.06      0.25      0.10      2079\n",
      "\n",
      "[[516 506 517 540]\n",
      " [  0   0   0   0]\n",
      " [  0   0   0   0]\n",
      " [  0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************\n",
      "Classifier= MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) and the ngrams is= 3\n",
      "Accuracy score is 0.74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.66      0.62       516\n",
      "           1       0.76      0.67      0.71       506\n",
      "           2       0.78      0.83      0.81       517\n",
      "           3       0.84      0.77      0.80       540\n",
      "\n",
      "    accuracy                           0.74      2079\n",
      "   macro avg       0.74      0.74      0.74      2079\n",
      "weighted avg       0.74      0.74      0.74      2079\n",
      "\n",
      "[[343 124  55  62]\n",
      " [ 73 341  15  19]\n",
      " [ 62  15 429  42]\n",
      " [ 38  26  18 417]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************\n",
      "Classifier= LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) and the ngrams is= 3\n",
      "Accuracy score is 0.71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.54      0.60       516\n",
      "           1       0.77      0.65      0.71       506\n",
      "           2       0.80      0.76      0.78       517\n",
      "           3       0.62      0.86      0.72       540\n",
      "\n",
      "    accuracy                           0.71      2079\n",
      "   macro avg       0.72      0.70      0.70      2079\n",
      "weighted avg       0.72      0.71      0.70      2079\n",
      "\n",
      "[[279  71  31  31]\n",
      " [ 67 331  17  16]\n",
      " [ 56  14 395  31]\n",
      " [114  90  74 462]]\n",
      "**************************************\n",
      "Classifier= BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True) and the ngrams is= 3\n",
      "Accuracy score is 0.43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.37      0.46       516\n",
      "           1       0.93      0.33      0.48       506\n",
      "           2       0.33      0.98      0.49       517\n",
      "           3       1.00      0.07      0.13       540\n",
      "\n",
      "    accuracy                           0.43      2079\n",
      "   macro avg       0.71      0.44      0.39      2079\n",
      "weighted avg       0.72      0.43      0.39      2079\n",
      "\n",
      "[[193  65   9  56]\n",
      " [ 11 166   1   1]\n",
      " [312 275 507 446]\n",
      " [  0   0   0  37]]\n",
      "**************************************\n",
      "Classifier= SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False) and the ngrams is= 3\n",
      "Accuracy score is 0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.55      0.61       516\n",
      "           1       0.76      0.67      0.71       506\n",
      "           2       0.81      0.81      0.81       517\n",
      "           3       0.66      0.86      0.74       540\n",
      "\n",
      "    accuracy                           0.72      2079\n",
      "   macro avg       0.73      0.72      0.72      2079\n",
      "weighted avg       0.73      0.72      0.72      2079\n",
      "\n",
      "[[284  69  26  30]\n",
      " [ 77 339  14  18]\n",
      " [ 54  14 420  30]\n",
      " [101  84  57 462]]\n",
      "**************************************\n",
      "Classifier= DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best') and the ngrams is= 3\n",
      "Accuracy score is 0.33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.04      0.08       516\n",
      "           1       1.00      0.08      0.14       506\n",
      "           2       0.69      0.20      0.31       517\n",
      "           3       0.28      0.96      0.43       540\n",
      "\n",
      "    accuracy                           0.33      2079\n",
      "   macro avg       0.67      0.32      0.24      2079\n",
      "weighted avg       0.66      0.33      0.24      2079\n",
      "\n",
      "[[ 21   8   1   0]\n",
      " [  0  39   0   0]\n",
      " [ 12  10 102  23]\n",
      " [483 449 414 517]]\n",
      "**************************************\n",
      "Classifier= RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features=1, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False) and the ngrams is= 3\n",
      "Accuracy score is 0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      1.00      0.40       516\n",
      "           1       0.33      0.00      0.00       506\n",
      "           2       0.00      0.00      0.00       517\n",
      "           3       0.00      0.00      0.00       540\n",
      "\n",
      "    accuracy                           0.25      2079\n",
      "   macro avg       0.15      0.25      0.10      2079\n",
      "weighted avg       0.14      0.25      0.10      2079\n",
      "\n",
      "[[514 505 517 540]\n",
      " [  2   1   0   0]\n",
      " [  0   0   0   0]\n",
      " [  0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************\n",
      "Classifier= KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
      "                     weights='uniform') and the ngrams is= 3\n",
      "Accuracy score is 0.35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.12      0.20       516\n",
      "           1       0.89      0.11      0.20       506\n",
      "           2       0.90      0.16      0.28       517\n",
      "           3       0.29      0.99      0.45       540\n",
      "\n",
      "    accuracy                           0.35      2079\n",
      "   macro avg       0.71      0.35      0.28      2079\n",
      "weighted avg       0.70      0.35      0.28      2079\n",
      "\n",
      "[[ 61  13   6   1]\n",
      " [  3  56   3   1]\n",
      " [  7   0  85   2]\n",
      " [445 437 423 536]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "ngrams = (1, 2, 3)\n",
    "\n",
    "results = []\n",
    "\n",
    "for g in ngrams:\n",
    "    #svc_model = GridSearchCV(pipe, param_grid, cv=3)\n",
    "    #svc_model.fit(X_train, Y_train)\n",
    "\n",
    "    #prediction = svc_model.predict(X_test)\n",
    "    \n",
    "\n",
    "    \n",
    "    for alg in classifiers:\n",
    "        pipeline = Pipeline([\n",
    "        ('vect', TfidfVectorizer(min_df=0.0001, max_df=0.95,\n",
    "                                 analyzer='word', lowercase=False,\n",
    "                                 ngram_range=(1, g))),\n",
    "        ('clf', alg), ])\n",
    "        pipeline.fit(X_train, Y_train)\n",
    "        feature_names = pipeline.named_steps['vect'].get_feature_names()\n",
    "        prediction = pipeline.predict(X_test)\n",
    "        print(f\"**************************************\")\n",
    "        print(f\"Classifier= \"+str(alg)+\" and the ngrams is= \"+str(g))\n",
    "        print(f\"Accuracy score is {accuracy_score(Y_test, prediction):.2f}\")\n",
    "        print(classification_report(Y_test, prediction))\n",
    "        # find accuracy, precision, recall:\n",
    "        new = np.asarray(Y_test)\n",
    "        print(confusion_matrix(prediction,Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
